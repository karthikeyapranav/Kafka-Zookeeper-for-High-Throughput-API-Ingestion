# Kafka + FastAPI High-Throughput Ingestion System

This project demonstrates a scalable event ingestion pipeline using **FastAPI**, **Apache Kafka**, **Zookeeper**, and **Docker**. It simulates high-throughput API traffic and processes events asynchronously using Kafka.

---

## ğŸ§© Architecture Overview

[FastAPI Producer] --> [Kafka Topic: events] --> [Kafka Consumer] --> [Logging / Processing]
^
[Zookeeper + Kafka (Docker)]


---

## ğŸ“¦ Project Structure

kafka-api-ingestion/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI server with /register_event and /get_status
â”‚
â”œâ”€â”€ consumer/
â”‚ â”œâ”€â”€ consumer.py # Kafka consumer that logs incoming events
â”‚ â””â”€â”€ consumer.log # Output log of processed events
â”‚
â”œâ”€â”€ simulate/
â”‚ â”œâ”€â”€ simulate_traffic.py # Script to simulate 10,000 event POSTs
â”‚
â”œâ”€â”€ docker-compose.yml # Sets up Kafka + Zookeeper
â”œâ”€â”€ README.md # This file
â””â”€â”€ summary.md # Project summary


---

## ğŸš€ How to Run

### 1ï¸âƒ£ Start Kafka and Zookeeper
```bash
docker-compose up -d

2ï¸âƒ£ Start FastAPI Server

cd app
uvicorn main:app --reload

3ï¸âƒ£ Start Kafka Consumer

cd consumer
python consumer.py


4ï¸âƒ£ Simulate Traffic


cd simulate
python simulate_traffic.py

ğŸ” API Endpoints
POST /register_event
Accepts a JSON event and pushes it to Kafka.

{
  "event_id": "abc123",
  "event_type": "click",
  "payload": {
    "user_id": "user_1",
    "action": "open_app"
  }
}

GET /get_status
Health check endpoint:

{"status": "API is running"}


ğŸ“ˆ What It Demonstrates
Handling high-throughput requests (10,000+)

Asynchronous event-driven architecture

Kafka integration with FastAPI

Logging processed events

Dockerized microservices setup

ğŸ›  Requirements
Python 3.8+

Docker & Docker Compose

kafka-python, fastapi, uvicorn, requests

ğŸ§  Learning Goals
Scalable API ingestion via Kafka

Decoupling producers and consumers

Real-world traffic simulation

Logging and observability practices